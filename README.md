# Project2: Continous control

## Introduction
Soloving the [Unity Robit Arm Game](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Learning-Environment-Examples.md#reacher) with DRL algorithm.
![Reacher](https://user-images.githubusercontent.com/10624937/43851024-320ba930-9aff-11e8-8493-ee547c6af349.gif)

In this environment, a double-jointed arm can move to target locations. The max time for each game is 1000 steps. In this project, the Reacher_One is used. <br>
State
  * A vector with 33 variables corresponding to position, rotation, velocity, and angular velocities of the arm.
Action
  * A vector with 4 variables, ranged from -1 to +1
Reward
  * +0.1 for each step that the agent's hand is in the goal location
### Project Goal: Attain average score 30+

## Setup
The workspace can be setup as following. <br>
`./build_env.sh`

## Run
1. To reproduce the result, run `python run.py`


## Implementation details

## Results

## Ideas for future works

